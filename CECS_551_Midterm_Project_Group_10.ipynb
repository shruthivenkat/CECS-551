{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KWMbWZTZ7q5-",
        "BwQp2wGP8_9Y",
        "G9uKhoh8-ToG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of AI4I 2020 Predictive Maintenance Dataset"
      ],
      "metadata": {
        "id": "GmM9hB8n7Wyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.\tDesign a decision tree based explainable model and provide an explanatory interface "
      ],
      "metadata": {
        "id": "KWMbWZTZ7q5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import xgboost\n",
        "#import matplotlib.pylab as plt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import tree, datasets, ensemble, model_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "from omnixai.data.tabular import Tabular\n",
        "from omnixai.preprocessing.tabular import TabularTransform\n",
        "from omnixai.explainers.tabular import TabularExplainer\n",
        "from omnixai.explainers.prediction import PredictionAnalyzer\n",
        "from omnixai.visualization.dashboard import Dashboard\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "5eBxrWU-oaiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "xH-6rYphoiC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update column names\n",
        "data.columns =  data.columns.str.replace(' ','_')\n",
        "data.columns =  data.columns.str.replace(r'\\[','', regex=True)\n",
        "data.columns =  data.columns.str.replace(r'\\]','', regex=True)\n",
        "data\n",
        "\n",
        "print(data.dtypes)\n",
        "# ignoring product_id\n",
        "data['Type'].unique()\n",
        "data.isnull().sum()\n",
        "\n",
        "# Replace type with integers since its categorical , can do One-hot encoding and apply column transformation.\n",
        "data.replace(['L', 'M', 'H'], [1, 2, 3], inplace=True)\n",
        "data.head()\n",
        "\n",
        "# Describe data\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "ZDSEunBror0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format data for classification\n",
        "X = data.drop(['UDI','Machine_failure', 'Product_ID'], axis=1).copy()\n",
        "# X = data.drop(['UDI','Machine_failure', 'Product_ID', 'TWF','HDF','PWF','OSF','RNF'], axis=1).copy()\n",
        "X.head()\n",
        "\n",
        "y = data['Machine_failure'].copy()\n",
        "y.head()\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "esAUXOGEo82e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data set to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "init_dtree = DecisionTreeClassifier(random_state=42)\n",
        "init_dtree = init_dtree.fit(X_train, y_train)\n",
        "\n",
        "plt.figure(figsize=(15, 7.5))\n",
        "plot_tree(init_dtree, filled=True, rounded=True, class_names=['fail 1', 'pass 0'], feature_names=X.columns)\n",
        "\n",
        "res = init_dtree.predict(X_test)\n",
        "score = accuracy_score(res, y_test)\n",
        "print('Decision Tree Accuracy:', score)"
      ],
      "metadata": {
        "id": "N3i9zpTUpEPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prune the decision tree because initial decision tree is HUGE\n",
        "path = init_dtree.cost_complexity_pruning_path(X_train,y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "pruned_dts = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    pruned_dt = DecisionTreeClassifier(random_state=0,ccp_alpha=ccp_alpha)\n",
        "    pruned_dt.fit(X_train, y_train)\n",
        "    pruned_dts.append(pruned_dt)"
      ],
      "metadata": {
        "id": "VTknPrANpL2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_scores = [pruned_dt.score(X_train, y_train) for pruned_dt in pruned_dts]\n",
        "test_scores = [pruned_dt.score(X_test, y_test) for pruned_dt in pruned_dts]\n",
        "fig,ax = plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for train, test sets\")\n",
        "ax.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle='steps-post')\n",
        "ax.plot(ccp_alphas, test_scores, marker='o', label='test', drawstyle='steps-post')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u2kKSHdBpShd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dt = DecisionTreeClassifier(random_state=42, ccp_alpha=0.0075)\n",
        "final_dt = final_dt.fit(X_train, y_train)\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "plot_tree(final_dt, filled=True, rounded=True, class_names=['fail 1', 'pass 0'], feature_names=X.columns)"
      ],
      "metadata": {
        "id": "2Pe4InaXpVoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final decision tree accuracy after pruning\n",
        "res = final_dt.predict(X_test)\n",
        "score = accuracy_score(res, y_test)\n",
        "print('Decision Tree Accuracy:', score)"
      ],
      "metadata": {
        "id": "CltAhXvypZLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruning tree to find the best hyperparameter value"
      ],
      "metadata": {
        "id": "8phNOtMKpmCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid = {\n",
        "    'criterion':  ['gini', 'entropy'],\n",
        "    'max_depth': range(1,4),\n",
        "    'min_samples_split': range(2,5),\n",
        "    'splitter': ['best', 'random'],\n",
        "    'min_samples_leaf': range(1,5)\n",
        "}\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "grid_cv = GridSearchCV(clf, grid, scoring=\"roc_auc\", n_jobs=-1, cv=3, verbose=1)\n",
        "grid_cv.fit(X_train, y_train)\n",
        "best_param = grid_cv.best_params_\n",
        "best_param"
      ],
      "metadata": {
        "id": "YMqyyVibpk-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dtree = DecisionTreeClassifier(criterion=best_param['criterion'], max_depth=best_param['max_depth'],min_samples_leaf=best_param['min_samples_leaf'],\n",
        "    min_samples_split=best_param['min_samples_split'],splitter=best_param['splitter'])\n",
        "\n",
        "new_dtree.fit(X_train, y_train)\n",
        "\n",
        "plt.figure(figsize=(15,7.5))\n",
        "plot_tree(new_dtree, filled=True, rounded=True, class_names=['1', '0'], feature_names=X.columns)"
      ],
      "metadata": {
        "id": "7t35tVGQpwtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = new_dtree.predict(X_test)\n",
        "score = accuracy_score(res, y_test)\n",
        "print('Decision Tree Accuracy:', score)"
      ],
      "metadata": {
        "id": "fpf3ICOZp05g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = xgboost.XGBClassifier(nthread=4,seed=42)\n",
        "\n",
        "# hyper params tuning\n",
        "parameters = {\n",
        "    'max_depth': range (2, 5, 1),\n",
        "    'n_estimators': range(60, 220, 40),\n",
        "    'learning_rate': [0.1, 0.01, 0.05]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=estimator,param_grid=parameters,scoring = 'roc_auc',n_jobs = 10,verbose=True)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VBXQIGczqGQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_search.best_params_)\n",
        "\n",
        "xgtree = grid_search.best_estimator_\n",
        "res = xgtree.predict(X_test)\n",
        "score = accuracy_score(res, y_test)\n",
        "\n",
        "print('Decision Tree Accuracy:', score)"
      ],
      "metadata": {
        "id": "VUbBgcqLqQZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SHAP Explainer**"
      ],
      "metadata": {
        "id": "oQNG_o0gqbCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv')\n",
        "data.columns =  data.columns.str.replace(' ','_')\n",
        "data.columns =  data.columns.str.replace(r'\\[','', regex=True)\n",
        "data.columns =  data.columns.str.replace(r'\\]','', regex=True)\n",
        "data.head()\n",
        "data.columns"
      ],
      "metadata": {
        "id": "itgItS0RqZUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = data.drop(['UDI', 'Product_ID'], axis=1).copy()\n",
        "processed_data"
      ],
      "metadata": {
        "id": "F45df0-tqi54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = list(processed_data.columns)\n",
        "print(feature_names)\n",
        "\n",
        "tabular_data = Tabular(\n",
        "    data=processed_data,\n",
        "    categorical_columns=['Type'],\n",
        "    target_column='Machine_failure'\n",
        ")\n",
        "\n",
        "tabular_data"
      ],
      "metadata": {
        "id": "xsRdjxGlqq5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "transformer = TabularTransform().fit(tabular_data)\n",
        "class_names = transformer.class_names\n",
        "x = transformer.transform(tabular_data)\n",
        "train, test, train_labels, test_labels = train_test_split(x[:, :-1], x[:, -1], train_size=0.80)\n",
        "print('Training data shape: {}'.format(train.shape))\n",
        "print('Test data shape:     {}'.format(test.shape))\n",
        "train_data = transformer.invert(train)\n",
        "test_data = transformer.invert(test)"
      ],
      "metadata": {
        "id": "15_W4zI1qvKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbtree = DecisionTreeClassifier( max_depth=7)\n",
        "gbtree.fit(train, train_labels)\n",
        "print('Test accuracy: {}'.format(accuracy_score(test_labels, gbtree.predict(test))))"
      ],
      "metadata": {
        "id": "PHGz9pQqqz7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = lambda z: transformer.transform(z)"
      ],
      "metadata": {
        "id": "Pa-uWOeWq4oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainers = TabularExplainer(\n",
        "    explainers=[\"lime\", \"shap\", \"mace\", \"pdp\", \"ale\"],\n",
        "    mode=\"classification\",\n",
        "    data=train_data,\n",
        "    model=gbtree,\n",
        "    preprocess=preprocess,\n",
        "    params={\n",
        "        \"lime\": {\"kernel_width\": 3},\n",
        "        \"shap\": {\"nsamples\": 100},\n",
        "        \"mace\": {\"ignored_features\": [\"UDI\", \"Product_ID\"]}\n",
        "    }\n",
        ")\n",
        "\n",
        "# Generate explanations\n",
        "test_instances = test_data[1653:1680]\n",
        "local_explanations = explainers.explain(X=test_instances)\n",
        "global_explanations = explainers.explain_global(\n",
        "    params={\"pdp\": {\"features\": ['Type', 'Air_temperature_K', 'Process_temperature_K', 'Rotational_speed_rpm', 'Torque_Nm', 'Tool_wear_min', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']}}\n",
        ")\n",
        "test_instances"
      ],
      "metadata": {
        "id": "CDWhYzbSq7Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=1\n",
        "print(\"LIME results:\")\n",
        "local_explanations[\"lime\"].ipython_plot(index, class_names=class_names)\n",
        "print(\"SHAP results:\")\n",
        "local_explanations[\"shap\"].ipython_plot(index, class_names=class_names)\n",
        "print(\"MACE results:\")\n",
        "local_explanations[\"mace\"].ipython_plot(index, class_names=class_names)\n",
        "print(\"PDP results:\")\n",
        "global_explanations[\"pdp\"].ipython_plot(class_names=class_names)\n",
        "print(\"ALE results:\")\n",
        "global_explanations[\"ale\"].ipython_plot(class_names=class_names)"
      ],
      "metadata": {
        "id": "h69JXq1Zq_w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = PredictionAnalyzer(\n",
        "    mode=\"classification\",\n",
        "    test_data=test_data,\n",
        "    test_targets=test_labels,\n",
        "    model=gbtree,\n",
        "    preprocess=preprocess\n",
        ")\n",
        "\n",
        "prediction_explanations = analyzer.explain()"
      ],
      "metadata": {
        "id": "IlK42kxorA92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, metrics in prediction_explanations.items():\n",
        "    print(f\"{name}:\")\n",
        "    metrics.ipython_plot(class_names=class_names)"
      ],
      "metadata": {
        "id": "qMuSaj3qrZjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch a dashboard for visualization\n",
        "dashboard = Dashboard(\n",
        "    instances=test_instances,\n",
        "    local_explanations=local_explanations,\n",
        "    global_explanations=global_explanations,\n",
        "    prediction_explanations=prediction_explanations,\n",
        "    class_names=class_names\n",
        ")\n",
        "\n",
        "dashboard.show()"
      ],
      "metadata": {
        "id": "H5YkR4rLrhej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.\tCompute the fairness of the model  "
      ],
      "metadata": {
        "id": "BwQp2wGP8_9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dalex as dx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "import plotly\n",
        "\n",
        "\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv')\n",
        "data.columns =  data.columns.str.replace(' ','_')\n",
        "data.columns =  data.columns.str.replace(r'\\[','', regex=True)\n",
        "data.columns =  data.columns.str.replace(r'\\]','', regex=True)\n",
        "data.head()\n",
        "\n",
        "processed_data = data.drop(['UDI', 'Product_ID'], axis=1).copy()\n",
        "processed_data.columns\n",
        "\n",
        "X = processed_data.drop(['Machine_failure'], axis=1).copy()\n",
        "y = processed_data['Machine_failure']\n",
        "\n",
        "categorical_features = ['Type']\n",
        "numerical_features = [ 'Air_temperature_K', 'Process_temperature_K',\n",
        "       'Rotational_speed_rpm', 'Torque_Nm', 'Tool_wear_min', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "preprocessor = ColumnTransformer(transformers=[('cat', categorical_transformer, categorical_features),\n",
        "        ('num', 'passthrough', numerical_features)])\n",
        "\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', XGBClassifier(learning_rate= 0.1, max_depth= 3, n_estimators= 140))])\n",
        "\n",
        "clf.fit(X, y)\n",
        "\n",
        "exp = dx.Explainer(clf, X, y)\n",
        "\n",
        "exp.model_performance().result\n",
        "\n",
        "failures = data.loc[data['Machine_failure'] >  0]\n",
        "failures['Type'].value_counts()\n",
        "protected = data['Type']\n",
        "privileged  = 'L' # since most failures are from L type\n",
        "\n",
        "fobject = exp.model_fairness(protected = protected, privileged=privileged)\n",
        "\n",
        "fobject.fairness_check(epsilon = 0.8)\n",
        "\n",
        "fobject.result\n",
        "\n",
        "fobject.plot()\n",
        "\n",
        "fobject.plot(type = 'metric_scores')\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, categorical_features),\n",
        "        ('num', numeric_transformer, numerical_features)])\n",
        "\n",
        "clf_forest = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', RandomForestClassifier(random_state=123, max_depth=5))]).fit(X,y)\n",
        "\n",
        "clf_logreg = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', LogisticRegression(random_state=123))]).fit(X,y)\n",
        "\n",
        "# create Explainer objects \n",
        "exp_forest  = dx.Explainer(clf_forest, X,y, verbose = False)\n",
        "exp_logreg  = dx.Explainer(clf_logreg, X,y, verbose = False)\n",
        "# create fairness explanations\n",
        "fobject_forest = exp_forest.model_fairness(protected, privileged)\n",
        "fobject_logreg = exp_logreg.model_fairness(protected, privileged)\n",
        "\n",
        "fobject.plot(objects=[fobject_forest, fobject_logreg])\n",
        "fobject.plot(objects=[fobject_forest, fobject_logreg], type = \"metric_scores\")\n",
        "\n",
        "fobject.parity_loss\n",
        "fobject.plot(objects=[fobject_forest, fobject_logreg], type = \"radar\")\n",
        "fobject.plot(objects=[fobject_forest, fobject_logreg], type = \"heatmap\")\n",
        "fobject.plot(objects=[fobject_forest, fobject_logreg], type = \"performance_and_fairness\")"
      ],
      "metadata": {
        "id": "7ZghcJJb9J1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.\tPerform a what-if analysis using CeterisParibus on the given dataset"
      ],
      "metadata": {
        "id": "G9uKhoh8-ToG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dalex as dx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "data = pd.read_csv('ai4i2020.csv', names = [\"UDI\", \"Product ID\", \"Type\",  \n",
        "            \"Air temperature [K]\", \"Process temperature [K]\", \"Rotational speed [rpm]\", \"Torque [Nm]\", \n",
        "                                        \"Tool wear [min]\", \"TWF\", \"HDF\", \"PWF\", \"OSF\", \"RNF\", \"Machine failure\"])\n",
        "\n",
        "X = data.drop(['UDI','Product ID','Machine failure'], axis=1)\n",
        "y = data[\"Machine failure\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=50)\n",
        "\n",
        "numerical_features = [\"Air temperature [K]\", \"Process temperature [K]\", \"Rotational speed [rpm]\", \"Torque [Nm]\", \"Tool wear [min]\", \"TWF\", \"HDF\", \"PWF\", \"OSF\", \"RNF\"]\n",
        "numerical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical_features = ['Type']\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "classifier = DecisionTreeClassifier(max_depth=4, criterion='entropy', max_features=0.6, splitter='best')\n",
        "\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('classifier', classifier)])\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "exp = dx.Explainer(clf, X_train, y_train)\n",
        "\n",
        "exp.predict(X_test)[:10]\n",
        "\n",
        "cp = exp.predict_profile(X_test.iloc[70], label='testing')\n",
        "cp.plot()\n",
        "\n",
        "print(accuracy_score(y_test, predictions))\n",
        "\n",
        "mp = exp.model_performance(model_type = 'classification')\n",
        "mp.result\n",
        "mp.plot(geom=\"roc\")"
      ],
      "metadata": {
        "id": "0PXKuyNF-aUy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}